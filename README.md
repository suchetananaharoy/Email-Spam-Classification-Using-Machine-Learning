Email communication has become an essential part of modern life, but the prevalence of spam messages poses significant challenges to both security and productivity. Spam emails often contain fraudulent, promotional, or malicious content, while legitimate (ham) emails are genuine communications. The ability to automatically distinguish between these two categories is therefore critical, and machine learning provides powerful tools for this task.

This project focuses on the Spam Email Classification Dataset available on Kaggle, which contains over 5,000 labeled email samples. Each entry consists of an email message and a binary label: spam (1) or ham (0). The dataset is relatively clean and balanced, making it suitable for experimentation with text classification algorithms. However, constraints include limited metadata (no sender or subject information) and the inherent sparsity of text features.

Preprocessing was a crucial step to ensure consistency and reduce noise. All text was converted to lowercase, punctuation and numbers were removed, and stopwords were eliminated to reduce dimensionality. Tokenization split messages into words, and stemming/lemmatization reduced them to their root forms. Feature extraction was performed using TF‑IDF (Term Frequency–Inverse Document Frequency), which captures both word frequency and importance, producing sparse matrices suitable for machine learning models.

The primary model implemented was the Multinomial Naive Bayes classifier, which assumes independence among features and is particularly effective for text data. Laplace smoothing was applied to handle unseen words, and log‑likelihood calculations ensured numerical stability. The model achieved strong results, with accuracy exceeding 96% and balanced precision and recall.

To extend the analysis, additional models were tested: Logistic Regression, Support Vector Machine (SVM), and Random Forest. Logistic Regression provided competitive accuracy with good interpretability, while SVM achieved slightly higher precision, reducing false positives. Random Forest, though robust, struggled with sparse high‑dimensional data and required more computational resources. An ensemble approach combining Naive Bayes and SVM further improved performance, achieving over 97% accuracy.

The findings highlight that Naive Bayes remains a reliable baseline for spam classification due to its simplicity and efficiency, while SVM offers superior precision at the cost of longer training times. Future improvements could involve deep learning models such as LSTMs or Transformers, which capture contextual meaning beyond word frequency.

In conclusion, this project demonstrates the effectiveness of classical machine learning algorithms in spam detection, provides comparative insights across multiple models, and underscores the importance of preprocessing and feature engineering in text classification tasks. 
